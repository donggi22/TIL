{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea3e08e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baa58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 작업 준비\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18688577",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf6e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = datasets.FashionMNIST(root='../data/',\n",
    "                              train=True,\n",
    "                              download=False,\n",
    "                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5012a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 60000\n",
    "tr_ds_loader = torch.utils.data.DataLoader(\n",
    "    dataset = tr_ds,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "img, _ = next(iter(tr_ds_loader))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8115aab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean(), img.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68c05fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7908f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Tensor화\n",
    "    transforms.Normalize(0.2860, 0.3530) # torch는 Normalize 전에 Tensor화 돼야 함!\n",
    "])\n",
    "\n",
    "tr_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        root='../data/',\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tt_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        root='../data/',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cf2f6",
   "metadata": {},
   "source": [
    "$$O=\\frac{I-F+2P}{S}+1$$\n",
    "\n",
    "```py\n",
    "28 * 28 * 1 # 입력 사이즈\n",
    "-> 24 * 24 * 10\n",
    "-> 12 * 12 * 10\n",
    "    -> 8 * 8 * 20\n",
    "    -> 4 * 4 * 20 = 320\n",
    "\n",
    "    # 또는 padding=same 일 때\n",
    "    -> 12 * 12 * 20\n",
    "    -> 6 * 6 * 20 = 720\n",
    "\n",
    "# --------------------------\n",
    "\n",
    "# 또는 padding=same 일 때\n",
    "28 * 28 * 1\n",
    "-> 28 * 28 * 10  \n",
    "-> 14 * 14 * 10  \n",
    "    -> 10 * 10 * 20  \n",
    "    -> 5 * 5 * 20 = 500\n",
    "\n",
    "    # 또는 padding=same 일 때\n",
    "    -> 14 * 14 * 20  \n",
    "    -> 7 * 7 * 20 = 980\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24298fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2)\n",
    "        x = F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0043cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "# 학습에서 스케줄 계획하는 건 학습률 외엔 거의 없음.\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1) # 가급적 에폭마다 스케줄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaca071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tr_ds_loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (x, y) in tr_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += len(data)\n",
    "        running_loss += loss.item() * len(data)\n",
    "        train_loss = running_loss / total\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        tr_ds_loader.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'train_accuracy': f'{train_accuracy * 100:.2f}%'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "814fed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, tt_ds_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    for data, target in tt_ds_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).item() * len(data)\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "    test_loss /= len(tt_ds_loader.dataset)\n",
    "    test_accuracy = correct / len(tt_ds_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83f7e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 1]: 100%|██████████| 938/938 [00:16<00:00, 56.57it/s, train_loss=0.4908, train_accuracy=82.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3798, test_accuracy: 86.09%, lr_scheduler[0.001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 2]: 100%|██████████| 938/938 [00:17<00:00, 52.30it/s, train_loss=0.4887, train_accuracy=82.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3796, test_accuracy: 86.20%, lr_scheduler[0.001]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 3]: 100%|██████████| 938/938 [00:16<00:00, 57.31it/s, train_loss=0.4857, train_accuracy=82.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3768, test_accuracy: 86.23%, lr_scheduler[0.0001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 3\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_bar = tqdm(\n",
    "        tr_ds_loader,\n",
    "        desc=f'[Epochs: {epoch}]',\n",
    "        leave=True\n",
    "        )\n",
    "    train(model, train_bar, optimizer)\n",
    "    scheduler.step()\n",
    "    test_loss, test_accuracy = evaluate(model, tt_ds_loader)\n",
    "\n",
    "    tqdm.write(\n",
    "        f'test_loss: {test_loss:.4f}, '\n",
    "        f'test_accuracy: {test_accuracy * 100:.2f}%, '\n",
    "        f'lr_scheduler{scheduler.get_last_lr()}'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb71ef4",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1713363",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_tr = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "tr_ds = datasets.CIFAR10(root='../data/',\n",
    "                 train=True,\n",
    "                 download=True,\n",
    "                 transform=ck_tr)\n",
    "\n",
    "tr_ds_loader = torch.utils.data.DataLoader(tr_ds,\n",
    "                                           batch_size=50000,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613f4fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck_data = iter(tr_ds_loader)\n",
    "data, _ = next(ck_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6802899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4914) tensor(0.2470)\n",
      "tensor(0.4822) tensor(0.2435)\n",
      "tensor(0.4465) tensor(0.2616)\n"
     ]
    }
   ],
   "source": [
    "print(data[:, 0].mean(), data[:, 0].std())\n",
    "print(data[:, 1].mean(), data[:, 1].std())\n",
    "print(data[:, 2].mean(), data[:, 2].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b2858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4914, 0.4822, 0.4465]), tensor([0.2470, 0.2435, 0.2616]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 코드를 한 번에!\n",
    "data.mean(dim=[0, 2, 3]), data.std(dim=[0, 2, 3]) # 0,2,3번 차원 전체를 뭉텅이로 축소하고 1번 차원(channel)만 남겨 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef5b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 설정\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f94fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수정 (노이즈 삽입)\n",
    "# 1. 데이터 준비\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "tr_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root='../data/',\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tt_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root='../data/',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d63511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(tr_ds_loader))\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels*2, 3) # 6, 30, 30\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool2d(2, 2) # 6, 15, 15\n",
    "        self.conv2 = nn.Conv2d(in_channels*2, in_channels*4, 3) # 12, 13, 13\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels*4)\n",
    "        self.conv3 = nn.Conv2d(in_channels*4, in_channels*8, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(in_channels*8)\n",
    "        self.fc = nn.Linear(in_channels*8*2*2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x))) # 6, 30, 30\n",
    "        out = self.mp(out) # 6, 15, 15\n",
    "        out = self.relu(self.bn2(self.conv2(out))) # 12, 13, 13\n",
    "        out = self.mp(out) # 12, 6, 6\n",
    "        out = self.relu(self.bn3(self.conv3(out))) # 24, 4, 4\n",
    "        out = self.mp(out) # 24, 2, 2\n",
    "        out = out.view(-1, 24*2*2)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = CNN_Model(3).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a3775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tr_ds_loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (x, y) in tr_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += len(data)\n",
    "        running_loss += loss.item() * len(data)\n",
    "        train_loss = running_loss / total\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        tr_ds_loader.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'train_accuracy': f'{train_accuracy * 100:.2f}%'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e14aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, tt_ds_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    for data, target in tt_ds_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).item() * len(data)\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "    test_loss /= len(tt_ds_loader.dataset)\n",
    "    test_accuracy = correct / len(tt_ds_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92bbadbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 1]: 100%|██████████| 782/782 [00:13<00:00, 56.76it/s, train_loss=1.5621, train_accuracy=43.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.4605, test_accuracy: 48.42%, lr_scheduler: 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 2]: 100%|██████████| 782/782 [00:14<00:00, 55.07it/s, train_loss=1.3375, train_accuracy=52.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.3064, test_accuracy: 54.34%, lr_scheduler: 0.1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 3]: 100%|██████████| 782/782 [00:15<00:00, 51.56it/s, train_loss=1.2734, train_accuracy=54.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.3322, test_accuracy: 52.75%, lr_scheduler: 0.0100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 3\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_bar = tqdm(\n",
    "        tr_ds_loader,\n",
    "        desc=f'[Epochs: {epoch}]',\n",
    "        leave=True\n",
    "        )\n",
    "    train(model, train_bar, optimizer)\n",
    "    scheduler.step()\n",
    "    test_loss, test_accuracy = evaluate(model, tt_ds_loader)\n",
    "\n",
    "    tqdm.write(\n",
    "        f'test_loss: {test_loss:.4f}, '\n",
    "        f'test_accuracy: {test_accuracy * 100:.2f}%, '\n",
    "        f'lr_scheduler: {scheduler.get_last_lr()[0]:.4f}' # scheduler.get_last_lr()가 [0.1] 이런 식으로 리스트로 return됨\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e257b7d",
   "metadata": {},
   "source": [
    "---\n",
    "ResNet 코드 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d69587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=5, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=10, bias=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "shortcut = nn.Sequential()\n",
    "shortcut((nn.Linear(5, 3), nn.Linear(3, 10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a770a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Linear' and 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mshortcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'Linear' and 'Sequential'"
     ]
    }
   ],
   "source": [
    "shortcut(nn.Linear(5, 10)) + nn.Sequential(nn.Linear(5, 10)) # layer 쟈체끼리의 덧셈은 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e77210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화 시 (레이어 정의)\n",
    "shortcut = nn.Sequential()  # 또는 Conv2d 등\n",
    "\n",
    "x = torch.randn(1, 64, 32, 32)\n",
    "\n",
    "# forward 시 (데이터 처리)\n",
    "out = nn.Conv2d(64, 64, 3, padding=1)(x) + shortcut(x) # layer의 출력끼리 덧셈은 가능\n",
    "#     ──────────────────────────────────   ───────────\n",
    "#                  텐서 결과                 텐서 결과\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a378b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (shortcut): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False), \n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "BasicBlock(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22682d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 1\n",
    "num_blocks = 2\n",
    "strides = [stride] + [1] * (num_blocks-1)\n",
    "strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "784d2a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 1\n",
    "num_blocks = 3\n",
    "strides = [stride] + [1] * (num_blocks-1)\n",
    "strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78f5aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 2\n",
    "num_blocks = 2\n",
    "strides = [stride] + [1] * (num_blocks-1)\n",
    "strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c7cb6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd7598",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 설계\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False) # same padding\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # out += x 시  이미지 크기나 채널 수가 다를 경우 shortcut으로 shape 맞춘 후 연산.\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes: # stride가 1이 아니거나 입력과 출력 채널수가 다를 때 \n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False), \n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module): # 층이 14개이므로 ResNet-14\n",
    "    def __init__(self, class_n):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16) # 16, 32, 32\n",
    "        self.l1 = self._make_l(16, 2, 1) # 16, 32, 32\n",
    "        self.l2 = self._make_l(32, 2, 1) # 32, 32, 32\n",
    "        self.l3 = self._make_l(64, 2, 1) # 64, 32, 32\n",
    "        self.out_l = nn.Linear(1024, class_n) # avgpool 때문에 64*(32/8)*(32/8) = 1024\n",
    "\n",
    "    def _make_l(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        l = []\n",
    "        for stride in strides:\n",
    "            l.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*l)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        # 분류기 층\n",
    "        x = F.avg_pool2d(x, 8)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.out_l(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faf91334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(10).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db56153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (l2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (l3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (out_l): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c003b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tr_ds_loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (x, y) in tr_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += len(data)\n",
    "        running_loss += loss.item() * len(data)\n",
    "        pred = (output.argmax(dim=1) == target)\n",
    "        correct += pred.sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        tr_ds_loader.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'train_accuracy': f'{train_accuracy*100:.2f}%'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07b92faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, tt_ds_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    for x, y in tt_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target).item()\n",
    "        test_loss += loss * len(data)\n",
    "        pred = (output.argmax(dim=1) == target)\n",
    "        correct += pred.sum().item()\n",
    "    test_loss /= len(tt_ds_loader.dataset)\n",
    "    test_accuracy = correct / len(tt_ds_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 1/20]: 100%|██████████| 782/782 [00:44<00:00, 17.51it/s, train_loss=2.1054, train_accuracy=24.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.8224, test_accuracy: 35.56%, lr: [0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 2/20]: 100%|██████████| 782/782 [00:42<00:00, 18.47it/s, train_loss=1.6438, train_accuracy=40.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.6426, test_accuracy: 41.25%, lr: [0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 3/20]: 100%|██████████| 782/782 [00:42<00:00, 18.49it/s, train_loss=1.4402, train_accuracy=48.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.4143, test_accuracy: 47.68%, lr: [0.010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 4/20]: 100%|██████████| 782/782 [00:42<00:00, 18.58it/s, train_loss=1.0878, train_accuracy=61.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.0760, test_accuracy: 61.89%, lr: [0.010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 5/20]: 100%|██████████| 782/782 [00:42<00:00, 18.41it/s, train_loss=1.0094, train_accuracy=64.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.9864, test_accuracy: 65.11%, lr: [0.010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 6/20]: 100%|██████████| 782/782 [00:42<00:00, 18.39it/s, train_loss=0.9514, train_accuracy=66.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.9516, test_accuracy: 66.73%, lr: [0.0010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 7/20]: 100%|██████████| 782/782 [00:42<00:00, 18.37it/s, train_loss=0.8668, train_accuracy=69.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8774, test_accuracy: 69.00%, lr: [0.0010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 8/20]: 100%|██████████| 782/782 [00:42<00:00, 18.33it/s, train_loss=0.8508, train_accuracy=70.39%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8675, test_accuracy: 69.33%, lr: [0.0010000000000000002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 9/20]: 100%|██████████| 782/782 [00:42<00:00, 18.58it/s, train_loss=0.8394, train_accuracy=70.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8608, test_accuracy: 69.80%, lr: [0.00010000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 10/20]: 100%|██████████| 782/782 [00:42<00:00, 18.59it/s, train_loss=0.8258, train_accuracy=71.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8525, test_accuracy: 69.89%, lr: [0.00010000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 11/20]: 100%|██████████| 782/782 [00:42<00:00, 18.61it/s, train_loss=0.8221, train_accuracy=71.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8513, test_accuracy: 69.90%, lr: [0.00010000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 12/20]: 100%|██████████| 782/782 [00:42<00:00, 18.34it/s, train_loss=0.8208, train_accuracy=71.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8509, test_accuracy: 70.02%, lr: [1.0000000000000004e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 13/20]: 100%|██████████| 782/782 [00:42<00:00, 18.47it/s, train_loss=0.8209, train_accuracy=71.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8507, test_accuracy: 69.95%, lr: [1.0000000000000004e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 14/20]: 100%|██████████| 782/782 [00:42<00:00, 18.34it/s, train_loss=0.8200, train_accuracy=71.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8513, test_accuracy: 69.94%, lr: [1.0000000000000004e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 15/20]: 100%|██████████| 782/782 [00:42<00:00, 18.26it/s, train_loss=0.8191, train_accuracy=71.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8509, test_accuracy: 69.99%, lr: [1.0000000000000004e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 16/20]:  95%|█████████▌| 744/782 [00:40<00:02, 18.72it/s, train_loss=0.8198, train_accuracy=71.48%]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_bar = tqdm(\n",
    "        tr_ds_loader,\n",
    "        desc=f'[Epochs: {epoch}/{EPOCHS}]',\n",
    "        leave=True\n",
    "    )\n",
    "    train(model, train_bar, optimizer)\n",
    "    scheduler.step()\n",
    "    test_loss, test_accuracy = evaluate(model, tt_ds_loader)\n",
    "    tqdm.write(\n",
    "        f'test_loss: {test_loss:.4f}, '\n",
    "        f'test_accuracy: {test_accuracy * 100:.2f}%, '\n",
    "        f'lr: {scheduler.get_last_lr()}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e3797",
   "metadata": {},
   "source": [
    "---\n",
    "코랩에서 공식 ResNet이랑 유사하게 구조 변경해서 재학습\n",
    "\n",
    "shortcut을 pointwise convolution으로 변경 및 _make_layer로 생성되는 l2, l3 layer의 stride=2로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ef41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 0. 작업 준비\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc2a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "ck_tr = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "tr_ds = datasets.CIFAR10(root='./data/',\n",
    "                 train=True,\n",
    "                 download=True,\n",
    "                 transform=ck_tr)\n",
    "\n",
    "tr_ds_loader = torch.utils.data.DataLoader(tr_ds,\n",
    "                                           batch_size=50000,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df7743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ck_data = iter(tr_ds_loader)\n",
    "data, _ = next(ck_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4914) tensor(0.2470)\n",
      "tensor(0.4822) tensor(0.2435)\n",
      "tensor(0.4465) tensor(0.2616)\n"
     ]
    }
   ],
   "source": [
    "print(data[:, 0].mean(), data[:, 0].std())\n",
    "print(data[:, 1].mean(), data[:, 1].std())\n",
    "print(data[:, 2].mean(), data[:, 2].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94e80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4914, 0.4822, 0.4465]), tensor([0.2470, 0.2435, 0.2616]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 위의 코드를 한 번에!\n",
    "data.mean(dim=[0, 2, 3]), data.std(dim=[0, 2, 3]) # 0,2,3번 차원 전체를 뭉텅이로 축소하고 1번 차원(channel)만 남겨 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2bb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 128\n"
     ]
    }
   ],
   "source": [
    "# 상수 설정\n",
    "if USE_CUDA:\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "print(f'BATCH_SIZE: {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수정 (노이즈 삽입)\n",
    "# 1. 데이터 준비\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # 데이터 증강\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "tr_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root='./data/',\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform=train_transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tt_ds_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root='./data/',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=test_transform\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604090e5",
   "metadata": {},
   "source": [
    "# ResNet-14\n",
    "공식적으로 ResNet에서 14layer 모델은 없음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf524081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 설계\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, padding=0, bias=False), # Shortcut은 spatial pattern 학습보다는 feature map의 차원 정렬과 downsampling을 위한 projection 역할(잔차 연결을 위한 지름길 역할)을 하므로 pointwise convolution을 사용\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, class_n):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False) # 16, 32, 32\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.l1 = self._make_layer(16, 2, 1) # 16, 32, 32\n",
    "        self.l2 = self._make_layer(32, 2, 2) # 32, 16, 16\n",
    "        self.l3 = self._make_layer(64, 2, 2) # 64, 8, 8\n",
    "        self.out_l = nn.Linear(64 * BasicBlock.expansion, class_n) # 64*1*1\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        l = []\n",
    "        for stride in strides:\n",
    "            l.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*l)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        # 분류기 층\n",
    "        # x = F.avg_pool2d(x, 8)\n",
    "        x = F.adaptive_avg_pool2d(x, 1) # 입력 크기와 무관하게 (1, 1)로 안전하게 pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.out_l(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538be0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(10).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tr_ds_loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (x, y) in tr_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += len(data)\n",
    "        running_loss += loss.item() * len(data)\n",
    "        pred = (output.argmax(dim=1) == target)\n",
    "        correct += pred.sum().item()\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        tr_ds_loader.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'train_accuracy': f'{train_accuracy*100:.2f}%'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad94856",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, tt_ds_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    for x, y in tt_ds_loader:\n",
    "        data, target = x.to(DEVICE), y.to(DEVICE)\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target).item()\n",
    "        test_loss += loss * len(data)\n",
    "        pred = (output.argmax(dim=1) == target)\n",
    "        correct += pred.sum().item()\n",
    "    test_loss /= len(tt_ds_loader.dataset)\n",
    "    test_accuracy = correct / len(tt_ds_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 1/160]: 100%|██████████| 391/391 [00:32<00:00, 12.04it/s, train_loss=1.6143, train_accuracy=39.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.4182, test_accuracy: 49.08%, lr: 0.1000, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 2/160]: 100%|██████████| 391/391 [00:29<00:00, 13.10it/s, train_loss=1.1545, train_accuracy=58.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.0657, test_accuracy: 61.14%, lr: 0.1000, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 3/160]: 100%|██████████| 391/391 [00:30<00:00, 13.02it/s, train_loss=0.9363, train_accuracy=66.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.9641, test_accuracy: 66.66%, lr: 0.0100, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 4/160]: 100%|██████████| 391/391 [00:30<00:00, 12.95it/s, train_loss=0.6927, train_accuracy=75.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.6639, test_accuracy: 76.82%, lr: 0.0100, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 5/160]: 100%|██████████| 391/391 [00:29<00:00, 13.11it/s, train_loss=0.6387, train_accuracy=77.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.6422, test_accuracy: 77.77%, lr: 0.0100, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 6/160]: 100%|██████████| 391/391 [00:29<00:00, 13.04it/s, train_loss=0.6103, train_accuracy=78.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.6022, test_accuracy: 79.25%, lr: 0.0010, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 7/160]: 100%|██████████| 391/391 [00:30<00:00, 12.88it/s, train_loss=0.5671, train_accuracy=80.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5787, test_accuracy: 80.17%, lr: 0.0010, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 8/160]: 100%|██████████| 391/391 [00:29<00:00, 13.04it/s, train_loss=0.5604, train_accuracy=80.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5770, test_accuracy: 80.12%, lr: 0.0010, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 9/160]: 100%|██████████| 391/391 [00:29<00:00, 13.09it/s, train_loss=0.5531, train_accuracy=80.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5716, test_accuracy: 80.11%, lr: 0.0001, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 10/160]: 100%|██████████| 391/391 [00:30<00:00, 12.94it/s, train_loss=0.5475, train_accuracy=81.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5712, test_accuracy: 80.27%, lr: 0.0001, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 11/160]: 100%|██████████| 391/391 [00:30<00:00, 12.86it/s, train_loss=0.5441, train_accuracy=81.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5682, test_accuracy: 80.46%, lr: 0.0001, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 12/160]: 100%|██████████| 391/391 [00:30<00:00, 12.90it/s, train_loss=0.5484, train_accuracy=80.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5693, test_accuracy: 80.40%, lr: 0.0000, ES_Patience: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 13/160]: 100%|██████████| 391/391 [00:30<00:00, 12.99it/s, train_loss=0.5467, train_accuracy=81.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5698, test_accuracy: 80.35%, lr: 0.0000, ES_Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 14/160]: 100%|██████████| 391/391 [00:30<00:00, 12.67it/s, train_loss=0.5478, train_accuracy=80.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5696, test_accuracy: 80.39%, lr: 0.0000, ES_Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 15/160]: 100%|██████████| 391/391 [00:30<00:00, 12.77it/s, train_loss=0.5487, train_accuracy=80.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5704, test_accuracy: 80.36%, lr: 0.0000, ES_Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epochs: 16/160]: 100%|██████████| 391/391 [00:30<00:00, 12.88it/s, train_loss=0.5449, train_accuracy=81.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5693, test_accuracy: 80.43%, lr: 0.0000, ES_Patience: 4/5\n",
      "Early Stopping이 동작하였습니다.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 160\n",
    "ES_PATIENCE = 5\n",
    "best_loss = float('inf')\n",
    "es_patience = 0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "\n",
    "    train_bar = tqdm(\n",
    "        tr_ds_loader,\n",
    "        desc=f'[Epochs: {epoch}/{EPOCHS}]',\n",
    "        leave=True\n",
    "    )\n",
    "    train(model, train_bar, optimizer)\n",
    "    scheduler.step()\n",
    "    test_loss, test_accuracy = evaluate(model, tt_ds_loader)\n",
    "    tqdm.write(\n",
    "        f'test_loss: {test_loss:.4f}, '\n",
    "        f'test_accuracy: {test_accuracy * 100:.2f}%, '\n",
    "        f'lr: {scheduler.get_last_lr()[0]:.4f}, '\n",
    "        f'ES_Patience: {es_patience}/{ES_PATIENCE}'\n",
    "    )\n",
    "\n",
    "    if best_loss > test_loss:\n",
    "        best_loss = test_loss\n",
    "        es_patience = 0\n",
    "    else:\n",
    "        es_patience += 1\n",
    "    if es_patience >= ES_PATIENCE:\n",
    "        print('Early Stopping이 동작하였습니다.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1220f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시스템 전체 논리 코어 수: 8\n",
      "시스템 전체 물리 코어 수: 4\n",
      "PyTorch로 설정한 스레드 수: 100\n"
     ]
    }
   ],
   "source": [
    "import torch, os, psutil\n",
    "\n",
    "print(\"시스템 전체 논리 코어 수:\", os.cpu_count())\n",
    "print(\"시스템 전체 물리 코어 수:\", psutil.cpu_count(logical=False))\n",
    "print(\"PyTorch로 설정한 스레드 수:\", torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7180b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch로 설정한 스레드 수: 12\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(12)\n",
    "print(\"PyTorch로 설정한 스레드 수:\", torch.get_num_threads()) # 실제 8개가 최대라서 12개로 하면 오버헤드 걸림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d06ed949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch로 설정한 스레드 수: 100\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(100)\n",
    "print(\"PyTorch로 설정한 스레드 수:\", torch.get_num_threads()) # 실제 8개가 최대라서 100개로 하면 오버헤드 걸림."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
