{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a721754",
   "metadata": {},
   "source": [
    "## 0) 준비: import + 초기화 유틸\n",
    "\n",
    "목적\n",
    "\n",
    "- ViT는 보통 가중치 초기화로 truncated normal(std=0.02) 관례를 씁니다.\n",
    "\n",
    "- (엄밀 버전은 timm 라이브러리가 더 낫지만, 정리용으로 간단 구현)\n",
    "\n",
    "$$\n",
    "erf(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt\n",
    "$$\n",
    "\n",
    "$$GELU(x) = x \\cdot \\Phi(x) = 0.5x \\left(1 + erf\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4e6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def trunc_nomal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):\n",
    "    # timm 스타일의 truncated normal 간단 구현\n",
    "    # (엄밀한 구현이 필요하면 timm.trunc_normal_ 사용 권장)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = 0.5 * (1.0 + math.erf((a - mean) / (std * math.sqrt(2.0)))) \n",
    "        u = 0.5 * (1.0 + math.erf((b - mean) / (std * math.sqrt(2.0))))\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "        tensor.erfinv_()\n",
    "        tensor.mul_(std * math.sqrt(2.0)).add_(mean)\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b965b",
   "metadata": {},
   "source": [
    "## 1) Patch Embedding: Patchify + Linear Projection\n",
    "\n",
    "**논문 단계**\n",
    "\n",
    "1. 이미지를 P×P 크기로 쪼개서 patch들을 만든다 (patchify)\n",
    "2. 각 patch를 펼쳐서 (P×P×C)\n",
    "3. Linear로 D차원 토큰으로 바꾼다\n",
    "\n",
    "**구현 포인트**\n",
    "\n",
    "- 실제 구현은 `Conv2d(kernel=P, stride=P)`가 위 3단계를 한 번에 수행합니다.\n",
    "- 출력은 Transformer가 먹기 좋은 **(B, N, D)** 토큰 시퀀스입니다.\n",
    "\n",
    "shape 흐름:\n",
    "\n",
    "- 입력: (B, C, H, W)\n",
    "- conv: (B, D, H/P, W/P)\n",
    "- flatten: (B, N, D) where N=(H/P)(W/P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = (img_size, img_size) if isinstance(img_size, int) else img_size\n",
    "        patch_size = (patch_size, patch_size) if isinstance(patch_size, int) else patch_size\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        assert img_size[0] % patch_size[0] == 0 and img_size[1] % patch_size[1] == 0, \\\n",
    "            \"img_size must be divisible by patch_size\"\n",
    "\n",
    "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "\n",
    "        # Conv2d로 patchify + linear projection 동시 수행\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, C, H, W)\n",
    "        x = self.proj(x) # (B, D, H/P, W/P), N = H/P * W/P\n",
    "        x = x.flatten(start_dim=2).transpose(1, 2) # (B, N, D) where N = num_patches, D = embed_dim\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0053de48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((2, 3, 4, 4)).flatten(2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245a934",
   "metadata": {},
   "source": [
    "## 2) MLP(Feed Forward): Linear → GELU → Linear\n",
    "\n",
    "**논문 단계**\n",
    "\n",
    "- Transformer block의 FFN/MLP 부분\n",
    "- hidden_dim = mlp_ratio * D (보통 4D)\n",
    "- GELU 활성화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
